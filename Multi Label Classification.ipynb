{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e6712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e8ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2536c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.read_csv('final_toxic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56aaac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made my username hardcore me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww match background colour im seemingly stuc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really trying edit war just this gu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>cant make real suggestion improvement wondered...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir my hero chance remember page thats</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  explanation edits made my username hardcore me...      0             0   \n",
       "1  daww match background colour im seemingly stuc...      0             0   \n",
       "2  hey man im really trying edit war just this gu...      0             0   \n",
       "3  cant make real suggestion improvement wondered...      0             0   \n",
       "4             sir my hero chance remember page thats      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3aa1b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f76976",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.dropna(inplace=True)\n",
    "final_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbe6eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159505, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2b089",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d1088",
   "metadata": {},
   "source": [
    "Counting number of comments in each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc90ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(final_data.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4d957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values=list(final_data.iloc[:,3:].sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30bd958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ['red', 'yellow', 'black', 'blue', 'orange','green']\n",
    "plt.bar(columns,values,color=c)\n",
    "plt.title('count of comments in each category')\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('count')\n",
    "plt.savefig('plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20c500",
   "metadata": {},
   "source": [
    "counting number of comments which belongs to multiple label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c592c799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY  PC\\AppData\\Local\\Temp\\ipykernel_3312\\3964306647.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  value=final_data.iloc[:,2:].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "value=final_data.iloc[:,2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac97c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count=value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2c1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count=labels_count.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16d3e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 3, 2, 4, 5, 6], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(labels_count.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bfa120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ['red', 'yellow', 'black', 'blue', 'orange','green']\n",
    "plt.bar(labels_count.index,labels_count,color=c)\n",
    "plt.title('count of comments in each category')\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb109ad",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b77c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "def80192",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(max_features=10000)\n",
    "vectors=vectorizer.fit_transform(final_data['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a962434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159505, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f1a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=model_selection.train_test_split(vectors,final_data.iloc[:,3:],test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e57d8",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8facfa",
   "metadata": {},
   "source": [
    "# Model1- Using Chain Classifier Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee2b31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6358143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=ClassifierChain(LogisticRegression(max_iter=1000))\n",
    "model1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e2b5291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9190420463094542"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model1.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e004ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.60      0.91      0.72      3033\n",
      " severe_toxic       0.16      0.55      0.25       139\n",
      "      obscene       0.68      0.89      0.77      1971\n",
      "       threat       0.12      0.72      0.20        25\n",
      "       insult       0.62      0.74      0.67      1963\n",
      "identity_hate       0.19      0.74      0.31       110\n",
      "\n",
      "    micro avg       0.58      0.85      0.69      7241\n",
      "    macro avg       0.39      0.76      0.49      7241\n",
      " weighted avg       0.61      0.85      0.70      7241\n",
      "  samples avg       0.05      0.05      0.05      7241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model1.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08771979",
   "metadata": {},
   "source": [
    "#  Model2-Using  LabelPowerset Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "765762aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16eb46c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(max_iter=1000),\n",
       "              require_dense=[True, True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LabelPowerset(LogisticRegression(max_iter=1000))\n",
    "model2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bc6917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9170776561063279"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model2.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82fb0fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.53      0.93      0.67      2635\n",
      " severe_toxic       0.11      0.51      0.18       106\n",
      "      obscene       0.59      0.91      0.72      1668\n",
      "       threat       0.05      0.70      0.09        10\n",
      "       insult       0.53      0.80      0.64      1586\n",
      "identity_hate       0.15      0.74      0.25        86\n",
      "\n",
      "    micro avg       0.50      0.88      0.64      6091\n",
      "    macro avg       0.33      0.76      0.43      6091\n",
      " weighted avg       0.53      0.88      0.66      6091\n",
      "  samples avg       0.04      0.05      0.04      6091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model2.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7a764",
   "metadata": {},
   "source": [
    "# Model3- Using Binary Relavance Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68670513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75de2ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=LogisticRegression(max_iter=1000),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=BinaryRelevance(LogisticRegression(max_iter=1000))\n",
    "model3.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3c2a381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176627936136421"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model3.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7588ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.60      0.91      0.72      3033\n",
      " severe_toxic       0.20      0.54      0.29       173\n",
      "      obscene       0.63      0.92      0.75      1740\n",
      "       threat       0.11      0.70      0.18        23\n",
      "       insult       0.52      0.83      0.64      1495\n",
      "identity_hate       0.18      0.73      0.29       105\n",
      "\n",
      "    micro avg       0.55      0.88      0.67      6569\n",
      "    macro avg       0.37      0.77      0.48      6569\n",
      " weighted avg       0.57      0.88      0.69      6569\n",
      "  samples avg       0.05      0.05      0.05      6569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model3.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15458a",
   "metadata": {},
   "source": [
    "# 4.Model-Classifier Chain Method using NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd30ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "270a4eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=MultinomialNB())"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4=ClassifierChain(MultinomialNB())\n",
    "model4.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce15dee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076527626849452"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model4.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6198efb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.49      0.93      0.64      2408\n",
      " severe_toxic       0.23      0.52      0.32       211\n",
      "      obscene       0.69      0.75      0.72      2329\n",
      "       threat       0.00      0.00      0.00         6\n",
      "       insult       0.68      0.69      0.68      2329\n",
      "identity_hate       0.54      0.20      0.29      1113\n",
      "\n",
      "    micro avg       0.56      0.71      0.63      8396\n",
      "    macro avg       0.44      0.52      0.44      8396\n",
      " weighted avg       0.59      0.71      0.62      8396\n",
      "  samples avg       0.04      0.04      0.04      8396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model4.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee9fe6",
   "metadata": {},
   "source": [
    "# Model5-  LabelPowerset Using  NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67b65a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5=LabelPowerset(MultinomialNB())\n",
    "model5.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d27f7f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906670567583382"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model5.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17d4be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.26      0.99      0.41      1209\n",
      " severe_toxic       0.00      0.00      0.00         0\n",
      "      obscene       0.38      0.95      0.54      1026\n",
      "       threat       0.00      0.00      0.00         0\n",
      "       insult       0.37      0.85      0.52      1026\n",
      "identity_hate       0.00      0.00      0.00         0\n",
      "\n",
      "    micro avg       0.29      0.93      0.44      3261\n",
      "    macro avg       0.17      0.46      0.24      3261\n",
      " weighted avg       0.33      0.93      0.48      3261\n",
      "  samples avg       0.02      0.02      0.02      3261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model5.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba9a9d",
   "metadata": {},
   "source": [
    "# Model6- BinaryRelevance using  NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb49cb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6=BinaryRelevance(MultinomialNB())\n",
    "model6.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bb35efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104530636128062"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model6.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78254dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.49      0.93      0.64      2408\n",
      " severe_toxic       0.07      0.64      0.13        53\n",
      "      obscene       0.49      0.91      0.64      1387\n",
      "       threat       0.00      0.00      0.00         0\n",
      "       insult       0.41      0.85      0.55      1145\n",
      "identity_hate       0.02      0.37      0.03        19\n",
      "\n",
      "    micro avg       0.43      0.90      0.58      5012\n",
      "    macro avg       0.25      0.62      0.33      5012\n",
      " weighted avg       0.46      0.90      0.61      5012\n",
      "  samples avg       0.03      0.05      0.04      5012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model6.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725fe0e7",
   "metadata": {},
   "source": [
    "# Model7- Using ChainClassifier SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb23357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec918d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7=ClassifierChain(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f32711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LinearSVC())"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19e1d337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9177881802223522"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model7.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8b797c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.67      0.86      0.75      3629\n",
      " severe_toxic       0.23      0.54      0.32       203\n",
      "      obscene       0.72      0.85      0.78      2149\n",
      "       threat       0.21      0.64      0.32        50\n",
      "       insult       0.63      0.73      0.67      2040\n",
      "identity_hate       0.29      0.62      0.39       192\n",
      "\n",
      "    micro avg       0.63      0.81      0.71      8263\n",
      "    macro avg       0.46      0.71      0.54      8263\n",
      " weighted avg       0.65      0.81      0.72      8263\n",
      "  samples avg       0.06      0.06      0.06      8263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model7.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471848b",
   "metadata": {},
   "source": [
    "# Model8- LabelPowerset using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe20feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8=LabelPowerset(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2822db19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LinearSVC(), require_dense=[True, True])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54621f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165343141352503"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model8.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e48a6654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.59      0.91      0.72      2990\n",
      " severe_toxic       0.13      0.31      0.18       196\n",
      "      obscene       0.65      0.86      0.74      1941\n",
      "       threat       0.20      0.65      0.30        46\n",
      "       insult       0.57      0.75      0.65      1798\n",
      "identity_hate       0.22      0.57      0.32       163\n",
      "\n",
      "    micro avg       0.56      0.83      0.67      7134\n",
      "    macro avg       0.39      0.68      0.49      7134\n",
      " weighted avg       0.58      0.83      0.68      7134\n",
      "  samples avg       0.05      0.05      0.05      7134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model8.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc61d9",
   "metadata": {},
   "source": [
    "# Model9-BinaryRelevance using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac6f807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9=BinaryRelevance(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba528e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=LinearSVC(), require_dense=[True, True])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a1e4b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.67      0.86      0.75      3629\n",
      " severe_toxic       0.25      0.56      0.34       210\n",
      "      obscene       0.70      0.88      0.78      2038\n",
      "       threat       0.20      0.60      0.30        52\n",
      "       insult       0.58      0.80      0.68      1723\n",
      "identity_hate       0.27      0.66      0.39       172\n",
      "\n",
      "    micro avg       0.62      0.84      0.71      7824\n",
      "    macro avg       0.45      0.73      0.54      7824\n",
      " weighted avg       0.64      0.84      0.72      7824\n",
      "  samples avg       0.06      0.06      0.06      7824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model9.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386df20",
   "metadata": {},
   "source": [
    "# 10.Model- Using Multioutput Classifier  XGBOOST(Tree ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d6661c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63157697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model10=MultiOutputClassifier(estimator=XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e01d4e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              gpu_id=None, grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None, ...))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "085af328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9178299757585889"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model10.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6dd50488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.59      0.90      0.72      3054\n",
      " severe_toxic       0.22      0.52      0.31       205\n",
      "      obscene       0.72      0.88      0.80      2095\n",
      "       threat       0.25      0.63      0.36        60\n",
      "       insult       0.56      0.79      0.66      1667\n",
      "identity_hate       0.27      0.63      0.38       181\n",
      "\n",
      "    micro avg       0.58      0.85      0.69      7262\n",
      "    macro avg       0.44      0.73      0.54      7262\n",
      " weighted avg       0.60      0.85      0.70      7262\n",
      "  samples avg       0.05      0.05      0.05      7262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model10.predict(X_test),Y_test,target_names=columns,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51564749",
   "metadata": {},
   "source": [
    "# Predication Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bad430b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9882a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(text):\n",
    "    sentence=re.sub(r'[^\\w\\s]','',text)\n",
    "    sentence=re.sub(r'[0-9]+','',sentence)\n",
    "    sentence=nltk.word_tokenize(sentence)\n",
    "    for word in sentence:\n",
    "        if word in stop_words:\n",
    "            sentence.remove(word)\n",
    "    lst=[]\n",
    "    for word in sentence:\n",
    "        lst.append(lemmatizer.lemmatize(word))\n",
    "    lst=' '.join(lst)\n",
    "    return model7.predict(vectorizer.transform([lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6286d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a text to predict whether its toxic or non-toxic :she is a bitch she cant even cook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=input('enter a text to predict whether its toxic or non-toxic :')\n",
    "predict_toxicity(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
